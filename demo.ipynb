{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a7397a4",
   "metadata": {},
   "source": [
    "# LLM Cover Letter Builder Demo\n",
    "\n",
    "This notebook demonstrates the implementation of a Retrieval Augmented Generation (RAG) system for building AI-powered cover letters using DeepSeek Chat API and LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a335d1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Section 1: Setup and Dependencies\n",
    "import langchain\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import chromadb\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "api_key = os.getenv('DEEPSEEK_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4279848",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Section 2: Document Processing\n",
    "# Load and split text\n",
    "loader = TextLoader(\"data/demo_data.txt\")\n",
    "documents = loader.load()\n",
    "\n",
    "# Configure text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "\n",
    "# Split documents into chunks\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# Initialize embedding model\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "# Create vector database\n",
    "vector_db = Chroma.from_documents(docs, embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4f9340",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96b0224",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9e0d64",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Section 3: Vector Database Operations\n",
    "def view_stored_documents(limit=5):\n",
    "    \"\"\"View documents stored in the vector database.\"\"\"\n",
    "    chroma_client = chromadb.PersistentClient(path=\"vector_db\")\n",
    "    collection = chroma_client.get_or_create_collection(name=\"documents\")\n",
    "    \n",
    "    stored_docs = collection.get(limit=limit)\n",
    "    \n",
    "    for i, (doc, metadata) in enumerate(zip(stored_docs[\"documents\"], stored_docs[\"metadatas\"])):\n",
    "        print(f\"Chunk {i+1}:\")\n",
    "        print(f\"Content: {doc}\")\n",
    "        print(f\"Metadata: {metadata}\\n\")\n",
    "\n",
    "def search_documents(query_text, n_results=3):\n",
    "    \"\"\"Search for relevant documents using semantic similarity.\"\"\"\n",
    "    chroma_client = chromadb.PersistentClient(path=\"vector_db\")\n",
    "    collection = chroma_client.get_or_create_collection(name=\"documents\")\n",
    "    \n",
    "    results = collection.query(\n",
    "        query_texts=[query_text],\n",
    "        n_results=n_results\n",
    "    )\n",
    "    \n",
    "    for i, (doc, metadata) in enumerate(zip(results[\"documents\"][0], results[\"metadatas\"][0])):\n",
    "        print(f\"Result {i+1}:\")\n",
    "        print(f\"Content: {doc}\")\n",
    "        print(f\"Metadata: {metadata}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d845b317",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Section 4: Keyword Extraction\n",
    "def extract_keywords_llm(text):\n",
    "    \"\"\"Extract keywords using LLM.\"\"\"\n",
    "    prompt = \"Extract keywords related to job description that would help in matching a potential resume to it. Return just a list of comma separated keywords\"\n",
    "    response = llm.invoke(f\"{prompt}\\n\\nJob Description:\\n{text}\")\n",
    "    return [kw.strip() for kw in response.content.split(',')]\n",
    "\n",
    "def extract_keywords_spacy(text):\n",
    "    \"\"\"Extract keywords using spaCy.\"\"\"\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(text)\n",
    "    keywords = set()\n",
    "    \n",
    "    # Extract noun chunks and named entities\n",
    "    keywords.update(chunk.text for chunk in doc.noun_chunks)\n",
    "    keywords.update(ent.text for ent in doc.ents)\n",
    "    \n",
    "    return list(keywords)\n",
    "\n",
    "def extract_keywords_yake(text, top_k=20):\n",
    "    \"\"\"Extract keywords using YAKE.\"\"\"\n",
    "    extractor = KeywordExtractor(lan=\"en\", n=3, top=top_k)\n",
    "    keywords = extractor.extract_keywords(text)\n",
    "    return [kw[0] for kw in keywords]\n",
    "\n",
    "def extract_keywords_tfidf(text, top_k=20):\n",
    "    \"\"\"Extract keywords using TF-IDF.\"\"\"\n",
    "    vectorizer = TfidfVectorizer(stop_words=\"english\", max_features=top_k)\n",
    "    X = vectorizer.fit_transform([text])\n",
    "    return vectorizer.get_feature_names_out()\n",
    "\n",
    "def extract_keywords_bert(text, top_n=20):\n",
    "    \"\"\"Extract keywords using KeyBERT.\"\"\"\n",
    "    kw_model = KeyBERT()\n",
    "    keywords = kw_model.extract_keywords(\n",
    "        text,\n",
    "        keyphrase_ngram_range=(1,3),\n",
    "        stop_words=\"english\",\n",
    "        top_n=top_n\n",
    "    )\n",
    "    return [kw[0] for kw in keywords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d038786",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Section 5: LLM Integration\n",
    "def generate_response(query, context):\n",
    "    \"\"\"Generate a response using the LLM based on the query and context.\"\"\"\n",
    "    prompt = f\"Answer using this context:\\n{context}\\n\\nQuestion: {query}\"\n",
    "    response = llm.invoke(prompt)\n",
    "    return response.content\n",
    "\n",
    "# Initialize LLM\n",
    "llm = ChatDeepSeek(\n",
    "    model=\"deepseek-chat\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=150,\n",
    "    timeout=30,\n",
    "    max_retries=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60700f9b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Section 6: Example Usage\n",
    "def generate_cover_letter(job_description, resume_keywords):\n",
    "    \"\"\"Generate a cover letter using the job description and resume keywords.\"\"\"\n",
    "    # Extract keywords from job description\n",
    "    jd_keywords = extract_keywords_llm(job_description)\n",
    "    \n",
    "    # Combine keywords for document search\n",
    "    search_query = \" \".join(jd_keywords + resume_keywords)\n",
    "    \n",
    "    # Retrieve relevant documents\n",
    "    retrieved_docs = vector_db.similarity_search(search_query, k=3)\n",
    "    context = \"\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "    \n",
    "    # Generate cover letter\n",
    "    prompt = f\"\"\"Based on the following job description and candidate's experience, generate a compelling cover letter:\n",
    "\n",
    "Job Description:\n",
    "{job_description}\n",
    "\n",
    "Candidate's Experience:\n",
    "{context}\n",
    "\n",
    "Please write a professional cover letter that highlights the candidate's relevant experience and skills.\"\"\"\n",
    "    \n",
    "    response = llm.invoke(prompt)\n",
    "    return response.content\n",
    "\n",
    "# Example usage\n",
    "job_description = \"\"\"We are looking for a Machine Learning Engineer with experience in Python, TensorFlow, \n",
    "and cloud computing (AWS/GCP). The ideal candidate should have a strong background in deep learning and \n",
    "natural language processing (NLP).\"\"\"\n",
    "\n",
    "resume_keywords = [\"machine learning\", \"NLP\", \"Python\", \"TensorFlow\", \"AWS\"]\n",
    "cover_letter = generate_cover_letter(job_description, resume_keywords)\n",
    "print(cover_letter)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
